# mpb-ml
Este repositÃ³rio contÃ©m o Modelo de Aprendizado de MÃ¡quina, Conjunto de Dados e CÃ³digo de Treinamento para AnÃ¡lise de ViÃ©s PolÃ­tico em VeÃ­culos de ComunicaÃ§Ã£o Brasileiros

# News Portal Scraper
Sistema de coleta automatizada de notÃ­cias dos principais portais jornalÃ­sticos do Brasil.

## ğŸ“° Sobre
Sistema que realiza scraping de colunas polÃ­ticas dos seguintes portais:

- G1
- CNN Brasil
- Folha de SÃ£o Paulo
- Gazeta do Povo
- IstoÃ‰
- MetrÃ³poles

## ğŸš€ InstalaÃ§Ã£o
### Clone o repositÃ³rio
```bash
git clone https://github.com/renatocecchetti/mpb-ml.git
cd mpb-ml
```

### Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

## ğŸ’» Como Usar
### Uso BÃ¡sico
```python
from news_portal_scraper import NewsPortalScraper

# Inicializa o scraper
scraper = NewsPortalScraper()

# Coleta de um portal especÃ­fico
g1_texts = scraper.scrape_g1(limit_per_columnist=100)
scraper.save_portal_texts('g1', g1_texts, 'g1_political_news.txt')

# Ou coleta de todos os portais
all_texts = scraper.scrape_all(limit_per_columnist=100)
for portal, texts in all_texts.items():
    scraper.save_portal_texts(portal, texts, f'{portal}_political_news.txt')
```
### MÃ©todos DisponÃ­veis
| MÃ©todo | DescriÃ§Ã£o |
|--------|-----------|
| `scrape_g1(limit_per_columnist=100)` | Coleta textos dos colunistas polÃ­ticos do G1 |
| `scrape_cnn(limit_pages=10)` | Coleta textos dos colunistas da CNN Brasil |
| `scrape_folha(limit_per_columnist=100)` | Coleta textos dos colunistas da Folha |
| `scrape_gazeta(limit_per_columnist=20)` | Coleta textos dos colunistas da Gazeta |
| `scrape_istoe(limit_per_columnist=100)` | Coleta textos dos colunistas da IstoÃ‰ |
| `scrape_metropoles(limit_per_columnist=20)` | Coleta textos dos colunistas do MetrÃ³poles |
| `scrape_all(limit_per_columnist=100)` | Coleta textos de todos os portais |
| `save_portal_texts(portal, texts, filename)` | Salva os textos coletados em arquivo |

### Exemplo de Coleta EspecÃ­fica
```python
# Coleta apenas da CNN Brasil
cnn_texts = scraper.scrape_cnn(limit_pages=10)
scraper.save_portal_texts('cnn', cnn_texts, 'cnn_political_news.txt')

# Coleta apenas da Folha com limite personalizado
folha_texts = scraper.scrape_folha(limit_per_columnist=50)
scraper.save_portal_texts('folha', folha_texts, 'folha_political_news.txt')
```
## ğŸ“‹ Requisitos
```bash
Python 3.7+
requests>=2.31.0
beautifulsoup4>=4.12.2
tqdm>=4.66.1
lxml>=4.9.3
```
## âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes
- O scraper respeita delays entre requisiÃ§Ãµes para evitar sobrecarga dos servidores
- Alguns portais podem requerer autenticaÃ§Ã£o para acesso completo ao conteÃºdo
- As classes CSS dos portais podem mudar, necessitando atualizaÃ§Ã£o do cÃ³digo
- O nÃºmero real de textos coletados pode ser menor que o limite definido

## ğŸ—ï¸ Estrutura do Projeto
```tree
news-portal-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ news_scraper.py
â”‚   â””â”€â”€ news_portal_scraper.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“ LicenÃ§a
Este projeto estÃ¡ licenciado sob a licenÃ§a Apache-2.0 license - veja o arquivo [LICENSE](http://www.apache.org/licenses/LICENSE-2.0) para detalhes.

## ğŸ¤ Contribuindo
ContribuiÃ§Ãµes sÃ£o bem-vindas!
